{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejecicio #1:    Operaciones Matriciales\n",
    "Dada una matriz en formato numpy array, donde cada fila de la matriz representa un vector matemático: \n",
    "* Computar las normas l0, l1, l2, l-infinito\n",
    "    * l0: número de elementos diferentes a cero en el vector\n",
    "    * l1-l2: \n",
    "    ![](https://latex.codecogs.com/svg.latex?%7B%5Ccolor%7BOrange%7D%20%5Cleft%20%5C%7C%20x%20%5Cright%20%5C%7C_%7Bp%7D%20%3D%20%5Cleft%20%28%20%5Csum_%7B1%7D%5E%7Bn%7D%20%5Cleft%20%7C%20x_%7Bi%7D%20%5Cright%20%7C%5Ep%20%5Cright%20%29%5E%7B%5Ctfrac%7B1%7D%7Bp%7D%7D%7D)\n",
    "    * l-infinito:\n",
    "     ![](https://latex.codecogs.com/svg.latex?%7B%5Ccolor%7BOrange%7D%20%5Cleft%20%5C%7C%20x%20%5Cright%20%5C%7C_%7B%5Cinfty%7D%20%3D%20max_%7Bi%7D%20%5Cleft%20%7C%20x_%7Bi%7D%20%5Cright%20%7C%7D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz = np.array([[1,0,3,4],[5,6,0,8,],[0,10,11,12],[13,14,0,16]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matriz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Norma L0\n",
    "# Una forma de hacerlo\n",
    "norma_0 = np.count_nonzero(matriz)\n",
    "\n",
    "# Otra forma de hacerlo\n",
    "norma_0_ = np.sum(matriz != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Norma L0: \", norma_0)\n",
    "print(\"Norma L0: \", norma_0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L1-L2\n",
    "\n",
    "# L1\n",
    "norma_1 = np.linalg.norm(matriz,1)\n",
    "print(\"Norma L1: \", norma_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2\n",
    "norma_2 = np.linalg.norm(matriz,2)\n",
    "print(\"Norma L2: \", norma_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Norma 1 - Noma 2 de la matriz: \", norma_1 - norma_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l-infinito\n",
    "norma_infinito = np.linalg.norm(matriz,np.inf)\n",
    "print(\"Norma infinito: \", norma_infinito)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejecicio #2:    Sorting :house:\n",
    "Dada una matriz en formato numpy array, donde cada fila de la matriz representa un vector matemático, se requiere computar la norma l2 de cada vector.\n",
    "Una vez obtenida la norma, se debe ordenar las mísmas de mayor a menor. Finalmente, obtener la matriz original ordenada por fila según la norma l2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, -2, 3], [-4, 5, -6], [7, -8, 9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_l2 = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rows in A:\n",
    "    # print(rows)\n",
    "    vec_l2 = np.append(vec_l2, np.linalg.norm(rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_norm2 = np.zeros((2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_norm2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_norm2[0] = vec_l2[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_norm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    mat_norm2[1, i] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_norm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los índices que ordenarían la fila 1 en orden descendente\n",
    "sorted_indices = np.argsort(mat_norm2[1])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordenar todas las filas de la matriz de acuerdo con estos índices\n",
    "sorted_mat_norm2 = mat_norm2[:, sorted_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted_mat_norm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reordenada = A[sorted_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reordenada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejecicio #3:    Indexing :house:\n",
    "El objetivo es construir un índice para identificadores de usuarios, es decir _id2idx_ e _idx2id_.\n",
    "Para ello crear una clase, donde el índice se genere en el constructor. Armar métodos _get_users_id_ y _get_users_idx_.\n",
    "\n",
    "* Identificadores de usuarios : users_id = [15, 12, 14, 10, 1, 2, 1]\n",
    "* Índice de usuarios : users_id = [0, 1, 2, 3, 4, 5, 4]\n",
    "```\n",
    "id2idx =  [-1     4     5    -1    -1    -1     -1    -1    -1    -1     3     -1      1    -1     2     0]\n",
    "          [ 0     1     2     3     4     5      6     7     8     9    10     11     12    13    14    15]\n",
    "\n",
    "id2idx[15] -> 0 ; id2idx[12] -> 1 ; id2idx[3] -> -1\n",
    "idx2id[0] -> 15 ; idx2id[4] -> 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserIndex:\n",
    "    def __init__(self, usuarios_id):\n",
    "        #self.user_index = {}\n",
    "        #maximo de un array de numpy\n",
    "        user_id_min = np.min(usuarios_id) # minimos\n",
    "        user_id_max = np.max(usuarios_id) # maximos\n",
    "        #array_id_idx = np.array([np.full(user_id_max+1, -1), np.arange(user_id_min-1, user_id_max+1)]) # array de minimos-1 a maximos+1\n",
    "        self.array_id_idx = np.array(np.full(user_id_max+1, -1))\n",
    "        print(self.array_id_idx)\n",
    "\n",
    "        #recorro los usuarios_id\n",
    "        for i in range(len(usuarios_id)):\n",
    "            if self.array_id_idx[usuarios_id[i]] == -1:\n",
    "                self.array_id_idx[usuarios_id[i]] = i\n",
    "\n",
    "        print(self.array_id_idx)\n",
    "        \n",
    "\n",
    "\n",
    "    def get_users_id(self, idx):\n",
    "        indice = np.where(self.array_id_idx == idx)\n",
    "        return indice\n",
    "\n",
    "    def get_users_idx(self, id):\n",
    "        id = self.array_id_idx[id]\n",
    "        return id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usuarios_id = [15, 12, 14, 10, 1, 2, 1]\n",
    "usuarios_indices = UserIndex(usuarios_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(usuarios_indices.get_users_id(0))  # Imprime: 12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(usuarios_indices.get_users_idx(14))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejecicio #4:    Precision, Recall, Accuracy :house:\n",
    "En los problemas de clasificación, se cuenta con dos arreglos, la **verdad** (ground truth) y la **predicción** (prediction). \n",
    "Cada elemento de los arreglos puede tomar dos valores: _True_ (representado por 1) y _False_ (representado por 0). \n",
    "Por lo tanto, se pueden definir cuatro variables:\n",
    "* True Positive (TP): la verdad es 1 y la predicción es 1.\n",
    "* True Negative (TN): la verdad es 0 y la predicción es 0.\n",
    "* False Negative (FN): la verdad es 1 y la predicción es 0.\n",
    "* False Positive (FP): la verdad es 0 y la predicción es 1.\n",
    "\n",
    "A partir de esas cuatro variables, se definen las siguientes métricas:\n",
    "* Precision = TP / (TP + FP)\n",
    "* Recall = TP / (TP + FN)\n",
    "* Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "Para los siguientes arreglos, representando la **verdad** y la **predicción**,\n",
    "calcular las métricas anteriores con operaciones vectorizadas en NumPy.\n",
    "* truth = [1,1,0,1,1,1,0,0,0,1]\n",
    "* prediction = [1,1,1,1,0,0,1,1,0,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "truth = np.array([1, 1, 0, 1, 1, 1, 0, 0, 0, 1])\n",
    "prediction = np.array([1, 1, 1, 1, 0, 0, 1, 1, 0, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = np.sum(np.logical_and(truth == 1, prediction == 1))\n",
    "TN = np.sum(np.logical_and(truth == 0, prediction == 0))\n",
    "FN = np.sum(np.logical_and(truth == 1, prediction == 0))\n",
    "FP = np.sum(np.logical_and(truth == 0, prediction == 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TP: \", TP)\n",
    "print(\"TN: \", TN)\n",
    "print(\"FN: \", FN)\n",
    "print(\"FP: \", FP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = TP / (TP + FP)\n",
    "print(\"Precision: \", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = TP / (TP + FN)\n",
    "print(\"Recall: \", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acurracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "print(\"Acurracy: \", acurracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejecicio #5:    Average Query Precision :house:\n",
    "En information retrieval o search engines, en general contamos con queries “q” y para cada “q” una lista de documentos que son verdaderamente relevantes. \n",
    "Para evaluar un search engine, es común utilizar la métrica **average query precision**.\n",
    "Tomando de referencia el siguiente ejemplo, calcular la métrica con NumPy utilizando operaciones vectorizadas.\n",
    "```\n",
    "q_id =             [1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4]\n",
    "predicted_rank =   [0, 1, 2, 3, 0, 1, 2, 0, 1, 2, 3, 4, 0, 1, 2, 3]\n",
    "truth_relevance =  [T, F, T, F, T, T, T, F, F, F, F, F, T, F, F, T] \n",
    "```\n",
    "* Precision para q_id 1 = 2 / 4\n",
    "* Precision para q_id 2 = 3 / 3\n",
    "* Precision para q_id 3 = 0 / 5\n",
    "* Precision para q_id 4 = 2 / 4\n",
    "\n",
    "**_average query precision_** = ((2/4) + (3/3) + (0/5) + (2/4)) / 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explicación paso a paso\n",
    "\n",
    "Los datos proporcionados se pueden interpretar como:\n",
    "\n",
    "- q_id representa el ID de la consulta.\n",
    "- predicted_rank representa el rango predicho de los documentos para cada consulta.\n",
    "- truth_relevance indica si el documento es relevante (T) o no (F).\n",
    "\n",
    "Usando estos datos, podemos calcular la precisión para cada consulta:\n",
    "\n",
    "1. Para q_id 1, tenemos 2 documentos relevantes (T) de 4 recuperados, por lo que la precisión es 0.5.\n",
    "2. Para q_id 2, tenemos 3 documentos relevantes (T) de 3 recuperados, por lo que la precisión es 1.0.\n",
    "3. Para q_id 3, no tenemos documentos relevantes (T) de 6 recuperados, por lo que la precisión es 0.\n",
    "4. Para q_id 4, tenemos 2 documentos relevantes (T) de 4 recuperados, por lo que la precisión es 0.5.\n",
    "\n",
    "Finalmente, calculamos la average query precision tomando el promedio de las precisiones individuales:\n",
    "\n",
    "**_average query precision_** = ((2/4) + (3/3) + (0/5) + (2/4)) / 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "q_id = np.array([1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4]) \n",
    "truth_relevance = np.array(['T', 'F', 'T', 'F', 'T', 'T', 'T', 'F', 'F', 'F', 'F', 'F', 'T', 'F', 'F', 'T'])\n",
    "\n",
    "truth_relevance_booleano = np.where(truth_relevance == 'T', 1, 0)\n",
    "#truth_relevance_booleano = truth_relevance == 'T'\n",
    "\n",
    "unicos_q_id = np.unique(q_id)\n",
    "\n",
    "print(\"Ids unicos:\",unicos_q_id)\n",
    "print(\"Vector de Truth pasados a 1 o 0:\",truth_relevance_booleano)\n",
    "print(\"\\n\")\n",
    "\n",
    "precision_q_id = np.zeros(len(unicos_q_id))\n",
    "# print(precision_q_id)\n",
    "# print(\"#################\")\n",
    "\n",
    "izq = 0\n",
    "der = 0\n",
    "suma = 0\n",
    "for i in range(len(unicos_q_id)):\n",
    "    #print(\"id:\",i+1)\n",
    "    cantidad_unicos = np.count_nonzero(q_id == i+1) # cuento cuantos hay\n",
    "    #print(\"Cantidad de ids unicos: \", cantidad_unicos)\n",
    "    izq = der\n",
    "    der = izq+cantidad_unicos\n",
    "\n",
    "    # print(\"Izq:\",izq, \"Der:\",der)\n",
    "    # print(\"Cada Trues y False\", truth_relevance_booleano[izq:der])    \n",
    "    for s in range(izq, der):\n",
    "        suma = suma + truth_relevance_booleano[s]\n",
    "    \n",
    "    #print(\"Suma: \", suma)\n",
    "    precision_q_id[i] = suma / cantidad_unicos\n",
    "    #print(\"\\n\")\n",
    "\n",
    "    suma = 0\n",
    "\n",
    "\n",
    "# print(\"4 primeros\", truth_relevance_booleano[0:4])\n",
    "# print(\"3 segundos\", truth_relevance_booleano[4:7])\n",
    "# print(\"3 segundos\", truth_relevance_booleano[7:12])\n",
    "# print(\"4 segundos\", truth_relevance_booleano[12:16])\n",
    "\n",
    "print(\"Precision por id: \", precision_q_id)\n",
    "average_precision = np.mean(precision_q_id)\n",
    "print(\"Average Precision: \", average_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejecicio #6:    Distancia a Centroides\n",
    "Dada una nube de puntos _X_ y centroides _C_, obtener la distancia entre\n",
    "cada vector _X_ y los centroides utilizando operaciones vectorizadas y broadcasting en NumPy.\n",
    "Utilizar como referencia los siguientes valores:\n",
    "```\n",
    "X = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "C = [[1, 0, 0], [0, 1, 1]]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mi Explicación** :\n",
    "\n",
    "Para un espacio de dimensión n, la distancia euclidiana entre un vector x y un centroide c se calcula de la siguiente manera:\n",
    "\n",
    "Resta el vector x y el centroide c. Esto da un nuevo vector que representa la diferencia entre los dos.\n",
    "Calcula el cuadrado de cada componente del vector de diferencia.\n",
    "Suma todos los componentes al cuadrado.\n",
    "Toma la raíz cuadrada de la suma.\n",
    "En términos de una ecuación, esto se ve así:\n",
    "\n",
    "```\n",
    "d(x, c) = sqrt((x1 - c1)^2 + (x2 - c2)^2 + ... + (xn - cn)^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "C = np.array([[1, 0, 0], [0, 1, 1]])\n",
    "\n",
    "distancias_X_C = np.zeros((X.shape[0], C.shape[0]))\n",
    "\n",
    "# X[0] = [1,2,3]\n",
    "# C[0] = [1,0,0]\n",
    "# 1.- Calculo con cada uno de los vectores de X con el primer vector de C\n",
    "# distancia_euclidea = sqrt((1-1)^2 + (2-0)^2 + (3-0)^2) = sqrt(0+4+9) = sqrt(13) = 3.605551275463989\n",
    "# distancia_euclidea = sqrt((4-1)^2 + (5-0)^2 + (6-0)^2) = sqrt(9+25+36) = sqrt(70) = 8.366600265340756\n",
    "# distancia_euclidea = sqrt((7-1)^2 + (8-0)^2 + (9-0)^2) = sqrt(36+64+81) = sqrt(181) = 13.45362404707371\n",
    "# 2.- Calculo con cada uno de los vectores de X con el vector vector de C\n",
    "# distancia_euclidea = sqrt((1-0)^2 + (2-1)^2 + (3-1)^2) = sqrt(1+1+4) = sqrt(6) = 2.449489742783178\n",
    "# distancia_euclidea = sqrt((4-0)^2 + (5-1)^2 + (6-1)^2) = sqrt(16+16+25) = sqrt(57) = 7.54983443527075\n",
    "# distancia_euclidea = sqrt((7-0)^2 + (8-1)^2 + (9-1)^2) = sqrt(49+49+64) = sqrt(162) = 12.727922061357855\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    for j in range(C.shape[0]):\n",
    "        distancias_X_C[i,j] = np.sqrt(np.sum((X[i]-C[j])**2))\n",
    "    \n",
    "print(\"Shape de distancias_X_C:\",distancias_X_C.shape)\n",
    "print(\"distancias_X_C:\\n\",distancias_X_C)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejecicio #7:    Etiquetar Cluster\n",
    "Obtener para cada fila en _X_, el índice de la fila en _C_ con distancia euclídea más pequeña. \n",
    "Es decir, para cada fila en _X_, determinar a qué cluster pertenece en C.\n",
    "_Hint_: usar np.argmin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice_minimo = np.argmin(distancias_X_C, axis=1)\n",
    "print(\"Indice minimo:\\n\",indice_minimo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio #8:   Implementación Básica de K-means\n",
    "K-means es uno de los algoritmos más básicos en Machine Learning no supervisado.\n",
    "Es un algoritmo de clusterización, que agrupa datos que comparten características similares.\n",
    "Recordemos que entendemos datos como _n_ realizaciones del vector aleatorio _X_.\n",
    "\n",
    "El algoritmo funciona de la siguiente manera:\n",
    "1. El usuario selecciona la cantidad de clusters a crear _n_.\n",
    "2. Se seleccionan _n_ elementos aleatorios de _X_ como posiciones iniciales del los centroides _C_.\n",
    "3. Se calcula la distancia entre todos los puntos en _X_ y todos los puntos en _C_.\n",
    "4. Para cada punto en _X_ se selecciona el centroide más cercano de _C_.\n",
    "5. Se recalculan los centroides _C_ a partir de usar las filas de _X_ que pertenecen a cada centroide. \n",
    "6. Se itera entre 3 y 5 una cantidad fija de veces o hasta que la posición de los centroides no cambie dada una tolerancia.\n",
    "\n",
    "Se debe por lo tanto implementar la función k_means(X, n) de manera tal que, al finalizar, devuelva la posición de los centroides\n",
    "y a qué cluster pertenece cada fila de _X_. \n",
    "\n",
    "_Hint_: para (2) utilizar funciones de np.random, para (3) y (4) usar los ejercicios anteriores, \n",
    "para (5) es válido utilizar un for. Iterar 10 veces entre (3) y (5).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` Mi explicación: ```\n",
    "\n",
    "1. Inicializar:\n",
    "   - Seleccionar K puntos como centroides iniciales (esto puede ser aleatorio o basado en alguna otra heurística).\n",
    "2. Repetir hasta la convergencia (es decir, hasta que los centroides no cambien después de una iteración) o hasta alcanzar un número máximo de iteraciones:\n",
    "   - Asignar cada punto al centroide más cercano. Esto se hace calculando la distancia entre cada punto y todos los centroides, y asignando el punto al centroide con la menor distancia.\n",
    "   - Actualizar los centroides. Cada nuevo centroide es el punto medio (o el promedio) de todos los puntos que se han asignado a ese cluster.\n",
    "3. Devolver los centroides finales y las asignaciones de cada punto a un cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# defino mis vectores\n",
    "#X = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])\n",
    "\n",
    "# Establecer una semilla para el generador de números aleatorios\n",
    "np.random.seed(0)\n",
    "\n",
    "# Generar 4 vectores aleatorios de longitud 3 con valores enteros entre 0 y 10\n",
    "X = np.random.randint(0, 100, size=(4, 3))\n",
    "print(\"Vectores de X:\\n\",X)\n",
    "print(\"Shape de X:\",X.shape)\n",
    "print(\"Filas de X:\",X.shape[0])\n",
    "print(\"Columnas de X:\",X.shape[1])\n",
    "\n",
    "# cantidad de clusters a crear\n",
    "n_clusters = 2\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Inicializo los centroides\n",
    "# Se seleccionan n elementos aleatorios de X como posiciones iniciales del los centroides C.\n",
    "np.random.seed(4)\n",
    "indices = np.random.choice(X.shape[0], n_clusters, replace=False)\n",
    "print(\"Indices:\",indices)\n",
    "centroides_C = X[indices]\n",
    "print(\"Centroides C:\\n\",centroides_C)\n",
    "\n",
    "print(\"\\n\")\n",
    "# defino las iteraciones\n",
    "max_iter = 10\n",
    "\n",
    "for ind in range(max_iter):\n",
    "    distancias = np.zeros((X.shape[0], centroides_C.shape[0]))\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(centroides_C.shape[0]):\n",
    "            # Se calcula la distancia entre todos los puntos en X y todos los puntos en C.\n",
    "            distancias[i,j] = np.sqrt(np.sum((X[i]-centroides_C[j])**2))\n",
    "    \n",
    "    # Para cada punto en X se selecciona el centroide más cercano de C.\n",
    "    centroide_cercano = np.argmin(distancias, axis=1)\n",
    "\n",
    "    # Actualizo los centroides\n",
    "    centroide_C_anteriores = centroides_C.copy()\n",
    "    for i in range(n_clusters):\n",
    "        centroides_C[i] = np.mean(X[centroide_cercano == i], axis=0)\n",
    "\n",
    "    # verifico la convergencia de los centroides\n",
    "    if np.all(centroides_C == centroide_C_anteriores):\n",
    "        break\n",
    "    \n",
    "print(distancias)\n",
    "\n",
    "print(\"Centroides C:\\n\",centroides_C)\n",
    "print(\"Cercanos:\\n\",centroide_cercano)\n",
    "print(\"Iteraciones:\",ind)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio #9:   Computar Métricas con \\_\\_call__ :house:\n",
    "En problemas de machine learning, es muy común que para cada predicción que obtenemos en nuestro dataset de verificacion y evaluacion, almacenemos en arreglos de numpy el resultado de dicha predicción, junto con el valor verdadero y parámetros auxiliares (como el ranking de la predicción y el query id). \n",
    "\n",
    "Luego de obtener todas las predicciones, podemos utilizar la información almacenada en los arreglos de numpy, para calcular todas las métricas que queremos medir en nuestro sistema. \n",
    "\n",
    "Una buena práctica para implementar esto en Python, es crear clases que hereden de una clase Metric “base” y que cada métrica implemente el método \\_\\_call__.\n",
    "\n",
    "Utilizar herencia, operador \\_\\_call__ y _kwargs_, para escribir un programa que permita calcular todas las métricas de los ejercicios anteriores mediante un for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Metric:\n",
    "    def __call__(self, predicciones, etiquetas):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class Precision(Metric):\n",
    "    def __call__(self, predicciones, etiquetas):\n",
    "        correctas = np.sum(predicciones == etiquetas) # sumo las correctas\n",
    "        total = len(etiquetas) # total de etiquetas\n",
    "        return correctas / total\n",
    "\n",
    "class True_positive(Metric):\n",
    "    def __call__(self, predicciones, etiquetas):\n",
    "        TP = np.sum(np.logical_and(etiquetas == 1, predicciones == 1))\n",
    "        return TP\n",
    "\n",
    "class True_negative(Metric):\n",
    "    def __call__(self, predicciones, etiquetas):\n",
    "        TN = np.sum(np.logical_and(etiquetas == 0, predicciones == 0))\n",
    "        return TN\n",
    "\n",
    "class False_negative(Metric):\n",
    "    def __call__(self, predicciones, etiquetas):\n",
    "        FN = np.sum(np.logical_and(etiquetas == 1, predicciones == 0))\n",
    "        return FN\n",
    "\n",
    "class False_positive(Metric):\n",
    "    def __call__(self, predicciones, etiquetas):\n",
    "        FP = np.sum(np.logical_and(etiquetas == 0, predicciones == 1))\n",
    "        return FP\n",
    "\n",
    "# Uso de las metricas\n",
    "presicion = Precision()\n",
    "tp = True_positive()\n",
    "tn = True_negative()\n",
    "fn = False_negative()\n",
    "fp = False_positive()\n",
    "\n",
    "predictions = np.array([1, 1, 0, 1, 1, 1, 0, 0, 0, 1])\n",
    "targets = np.array([1, 1, 1, 1, 0, 0, 1, 1, 0, 0])\n",
    "\n",
    "print(\"Precision:\",presicion(predictions, targets))\n",
    "print(\"Verdaderos Positivos:\",tp(predictions, targets))\n",
    "print(\"Verdaderos Negativos:\",tn(predictions, targets))\n",
    "print(\"Falsos Negativos:\",fn(predictions, targets))\n",
    "print(\"Falsos Positivos:\",fp(predictions, targets))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejercicio #10:   Dataset a NumPy Estructurado - Patrón de Diseño Singleton :house:\n",
    "Para éste ejercicio vamos a descargar un dataset de Kaggle. Es recomendable que se creen una cuenta porque es un lugar de donde potencialmente vamos a descargar muchos recursos.\n",
    "\n",
    "Pueden descargar el dataset desde [aquí](https://www.kaggle.com/rounakbanik/the-movies-dataset/data?select=ratings.csv).\n",
    "\n",
    "El objetivo del ejercicio es crear una clase que permita realizar las siguientes funciones sobre el dataset:\n",
    "* Crear la estructura de un structured numpy array para el dataset.\n",
    "* Leer el csv, almacenar la información en el array estructurado.\n",
    "* Guardar el array estructurado en formato .pkl.\n",
    "* Crear una instancia singleton del array estructurado (utilizando \\_\\_new__ e \\_\\_init__).\n",
    "* Al crear la instancia, si se encuentra el .pkl cargar desde el pkl. Si el .pkl no está, comenzar por transformar el .csv en .pkl y luego levantar la información.\n",
    "* Encontrar una forma de optimizar la operación usando generators [opcional].\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Crear la estructura de un structured numpy array para el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_tipo = np.dtype(\n",
    "    [\n",
    "        ('userId', np.int64), \n",
    "        ('movieId', np.int64), \n",
    "        ('rating', np.float64),\n",
    "        ('timestamp', np.int64)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Leer el csv, almacenar la información en el array estructurado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Usar numpy.loadtxt para leer el archivo CSV\n",
    "data = np.loadtxt('input/ratings_small.csv', delimiter=',', dtype=dt_tipo, skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Usa genfromtxt para leer el archivo CSV\n",
    "# data = np.genfromtxt('input/ratings_small.csv', delimiter=',', dtype=dt_tipo, skip_header=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Guardar el array estructurado en formato .pkl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Guardo el dataset en un archivo binario\n",
    "with open('input/ratings_small.pkl', 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Crear una instancia singleton del array estructurado (utilizando \\_\\_new__ e \\_\\_init__).\n",
    "\n",
    "- En Python, los singletons son una clase de diseño que restringe la creación de una clase a una sola instancia. Para crear una instancia singleton de un array estructurado en numpy\n",
    "\n",
    "- Para optimizar la operación, podemos utilizar un generador para leer el archivo CSV en bloques en lugar de cargar todo el archivo en memoria a la vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingletonArray:\n",
    "    _instance = None\n",
    "\n",
    "    dt_tipo = np.dtype(\n",
    "    [\n",
    "        ('userId', np.int64), \n",
    "        ('movieId', np.int64), \n",
    "        ('rating', np.float64),\n",
    "        ('timestamp', np.int64)\n",
    "        ])\n",
    "\n",
    "    def __new__(cls, *args, **kwargs):\n",
    "        if not cls._instance:\n",
    "            cls._instance = super(SingletonArray, cls).__new__(cls)\n",
    "        return cls._instance\n",
    "\n",
    "    def __init__(self, csv_path, pkl_path):\n",
    "        self.csv_path = csv_path\n",
    "        self.pkl_path = pkl_path\n",
    "        if os.path.exists(self.pkl_path):\n",
    "            with open(self.pkl_path, 'rb') as f:\n",
    "                self.array = pickle.load(f)\n",
    "        else:\n",
    "            self._leer_csv_y_crear_pkl()\n",
    "\n",
    "    def _leer_csv_y_crear_pkl(self):\n",
    "        self.array = np.loadtxt(self.csv_path, delimiter=',', dtype=self.dt_tipo, skiprows=1)\n",
    "        # Guardar el array en un archivo .pkl\n",
    "        with open('input/ratings_small.pkl', 'wb') as f:\n",
    "            pickle.dump(self.array, f)\n",
    "        return self.array\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Uso:\n",
    "singleton_array = SingletonArray('input/ratings_small.csv', 'input/ratings_small.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(  1,   31, 2.5, 1260759144) (  1, 1029, 3. , 1260759179)\n",
      " (  1, 1061, 3. , 1260759182) ... (671, 6365, 4. , 1070940363)\n",
      " (671, 6385, 2.5, 1070979663) (671, 6565, 3.5, 1074784724)]\n"
     ]
    }
   ],
   "source": [
    "print(singleton_array.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(  1,   31, 2.5, 1260759144), (  1, 1029, 3. , 1260759179),\n",
       "       (  1, 1061, 3. , 1260759182), ..., (671, 6365, 4. , 1070940363),\n",
       "       (671, 6385, 2.5, 1070979663), (671, 6565, 3.5, 1074784724)],\n",
       "      dtype=[('userId', '<i8'), ('movieId', '<i8'), ('rating', '<f8'), ('timestamp', '<i8')])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "singleton_array.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
